# SPDX-FileCopyrightText: 2002-2025 Lawrence Livermore National Laboratory & other contributors to SLURM <https://github.com/SchedMD/slurm/commits/master/DISCLAIMER>
# SPDX-License-Identifier: GPL-2.0-or-later
# SPDX-PackageName: slurm-containers
diff --git a/slurm/slurm.h b/slurm/slurm.h
index ae1bc97d72..876593f3b4 100644
--- a/slurm/slurm.h
+++ b/slurm/slurm.h
@@ -3182,6 +3182,7 @@ typedef struct {
 	uint16_t vsize_factor;	/* virtual memory limit size factor */
 	uint16_t wait_time;	/* default job --wait time */
 	char *x11_params;	/* X11Parameters */
+	char *job_skip_ids;	/* list of job ids to skip */
 } slurm_conf_t;

 typedef struct slurmd_status_msg {
diff --git a/src/api/config_info.c b/src/api/config_info.c
index b6f5d5e8cc..fd7c6df333 100644
--- a/src/api/config_info.c
+++ b/src/api/config_info.c
@@ -1237,6 +1237,8 @@ extern void *slurm_ctl_conf_2_key_pairs(slurm_conf_t *conf)

 	add_key_pair(ret_list, "X11Parameters", "%s", conf->x11_params);

+	add_key_pair(ret_list, "SlurmJobSkipIds", "%s", conf->job_skip_ids);
+
 	return ret_list;
 }

diff --git a/src/common/read_config.c b/src/common/read_config.c
index a34dd39a47..2ac5de7a8b 100644
--- a/src/common/read_config.c
+++ b/src/common/read_config.c
@@ -437,6 +437,7 @@ s_p_options_t slurm_conf_options[] = {
 	{"VSizeFactor", S_P_UINT16},
 	{"WaitTime", S_P_UINT16},
 	{"X11Parameters", S_P_STRING},
+	{"SlurmJobSkipIds", S_P_STRING},

 	{"DownNodes", S_P_ARRAY, _parse_downnodes, _destroy_downnodes},
	{"NodeName", S_P_ARRAY, _parse_nodename, _destroy_nodename},
@@ -2711,6 +2712,7 @@ extern void free_slurm_conf(slurm_conf_t *ctl_conf_ptr, bool purge_node_hash)
 	xfree (ctl_conf_ptr->unkillable_program);
 	xfree (ctl_conf_ptr->version);
 	xfree (ctl_conf_ptr->x11_params);
+	xfree (ctl_conf_ptr->job_skip_ids);

 	if (purge_node_hash)
 		_free_name_hashtbl();
@@ -2909,7 +2911,8 @@ void init_slurm_conf(slurm_conf_t *ctl_conf_ptr)
 	xfree (ctl_conf_ptr->x11_params);
	ctl_conf_ptr->prolog_timeout = NO_VAL16;
	ctl_conf_ptr->epilog_timeout = NO_VAL16;
-
+	xfree(ctl_conf_ptr->job_skip_ids);
+
 	_free_name_hashtbl();

	return;
@@ -3771,6 +3774,8 @@ static int _validate_and_set_defaults(slurm_conf_t *conf,

 	(void) s_p_get_string(&conf->authinfo, "AuthInfo", hashtbl);

+	(void) s_p_get_string(&conf->job_skip_ids, "SlurmJobSkipIds", hashtbl);
+
 	if (!s_p_get_string(&conf->authtype, "AuthType", hashtbl))
 		conf->authtype = xstrdup(DEFAULT_AUTH_TYPE);

diff --git a/src/slurmctld/job_mgr.c b/src/slurmctld/job_mgr.c
index e0317dd188..6b41e7d90c 100644
--- a/src/slurmctld/job_mgr.c
+++ b/src/slurmctld/job_mgr.c
@@ -1486,6 +1486,30 @@ extern int job_mgr_dump_job_state(void *object, void *arg)
 	return 0;
 }

+// Function to check if a skip_id exists in env provided by user
+int contains_skip_id(char* job_skip_ids, int job_id) {
+	// check if variable is null
+	if (job_skip_ids == NULL || (*job_skip_ids == '\0')) {
+		return 0;
+	}
+
+	char* dup = xstrdup(job_skip_ids); //duplicate
+	// Tokenize the string using a comma as delimiter
+	char* token = strtok(dup, ",");
+	// Loop through all the tokens
+	while (token != NULL) {
+		int num_val = atoi(token);  // Convert token to integer
+		// Compare the current number with the job_id
+		if (num_val == job_id) {
+			xfree(dup);
+			return 1;  // Found job_id
+		}
+		token = strtok(NULL, ",");  // Get next token
+	}
+	xfree(dup);
+	return 0;  // job_id not found
+}
+
 extern int job_mgr_load_job_state(buf_t *buffer,
 				  uint16_t protocol_version)
 {
@@ -1508,6 +1532,19 @@ extern int job_mgr_load_job_state(buf_t *buffer,
 		goto unpack_error;
 	}

+	// get SlurmJobSkipIds from slurm.conf
+	char* job_skip_ids = slurm_conf.job_skip_ids;
+	// check if  the current job id matches the job skip ids
+	if (contains_skip_id(job_skip_ids, job_ptr->job_id)) {
+		// set the return code to success, delete the job record,
+		verbose("deleting job id: %d", job_ptr->job_id);
+		// goto the end of the function
+		rc = SLURM_SUCCESS;
+		job_record_delete(job_ptr);
+		job_ptr = NULL;
+		goto free_it;
+	}
+
 	if (find_job_record(job_ptr->job_id)) {
 		error("duplicate job state record found for %pJ", job_ptr);
 		goto unpack_error;
